# **Installation**

This guide outlines the steps to set up your environment, install necessary libraries, and structure your project for fine-tuning and inference using Azure ML Service as the backend and ONNX Runtime for samples.

## **1. Set Python Env**
Create and activate a new Conda environment with Python 3.10.12.

```bash


conda create -n slmopsenv python==3.10.12

conda activate slmopsenv


```

## **2. Install Python Library**

Install the required Python libraries from the requirements.txt file.

```bash

pip install -r requirements.txt

```


## **3. Structure**

Your project structure is in the following directories:

```md

|--📁 QA_E2E
    |-📁 datasets
    |-📁 fine-tuning
    |-📁 inferences
    |-📁 models-cache
    
```

**📁 datasets** - Store the data that needs fine-tuning as JSON format files.

**📁 fine-tuning** - : Store Microsoft Olive settings in `olive-config.json` and save a cache of related steps.

**📁 inferences** - Store inference models and test results.

**📁 models-cache** - Save fine-tuned Microsoft Phi-3 mini models








