## Demo-02 : Fine-tuning Phi-3 with AI Tools VSCode Extensions

Using Azure AI Tools & Microsoft VS Code 

This demo guides you through the process of fine-tuning the Phi-3 model using AI Tools VSCode Extensions, including steps for fine-tuning, inference, and deployment using Azure Machine Learning Service. Ensure your Azure subscription has access to an Azure Compute A100 GPU to complete this demo.

This demo provides a structured approach to fine-tuning the Phi-3 model using AI Tools VSCode Extensions and deploying it with Azure Machine Learning Service

***Note*** Please Ensure your Azure Subscription has access to an Azure Compute A100 GPU to complete this demo.

**Sample Code**

| Step | Description | Operation |
|-------------------|----------------------------------|-------------------|
|01.Installation| Please follow this step to set your env|[Go](./qa_e2e/docs/01.Installation.md)|
|02.Prepare your QA datasets| Prepare your datasets, and tell you how to clean your datasets|[Go](./qa_e2e/docs/02.PrepareDatasets.md)|
|03.Use Microsoft Olive to architect SLMOps | Using Microsoft Olive tools to fit your SLMOps cycle|[Go](./qa_e2e/docs/03.E2E_LoRA&QLoRA_Config_With_Olive.md)|
|04.Inference your Fine-tuning models| Inference your onnx model after fine tuning|[Go](./qa_e2e/docs/04.E2E_Inference_ORT.md)|
